{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9b61ca09-df53-48a9-ae2b-b80ce5f8eea0",
   "metadata": {},
   "source": [
    "<center><a href=\"https://www.pieriantraining.com/\" ><img src=\"../PTCenteredPurple.png\" alt=\"Pierian Training Logo\" /></a></center>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c3eff5f5-eafc-42b8-8c56-f5cd28215311",
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8f0743f6-f1ba-41f2-ac59-8c257a82eeb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9771dcf6-7eae-426e-9f0d-d404d9369324",
   "metadata": {},
   "source": [
    "### Can LLMs do math?\n",
    "\n",
    "If LLMs are just predicting next most likely tokens, can they actually solve math problems? Or would they hallucinate the answer?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fe547900-bf6d-443a-a83c-1dd9984bbedc",
   "metadata": {},
   "outputs": [],
   "source": [
    "answer = 123456 * 456789"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "823765c3-66d8-47e9-9b2f-5457c34df8f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56393342784"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "98dbcba2-5bf1-4d51-870e-87aa6648c6c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "    {'role':'system','content':'You help solve math problems'},\n",
    "    {'role':'user','content':'What is 123456 times 456789?'}\n",
    "    ]\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "8fda0e30-4365-464a-a539-2310935dc06c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 123456 and 456789 is:\n",
      "\n",
      "56,493,706,784\n"
     ]
    }
   ],
   "source": [
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "983b74d7-3e55-41bc-806a-eaa0a1643ce5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 123456 multiplied by 456789 is 56,390,469,024.\n"
     ]
    }
   ],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "    {'role':'system','content':'You help solve math problems'},\n",
    "    {'role':'user','content':'What is 123456 * 456789?'}\n",
    "    ]\n",
    "\n",
    ")\n",
    "\n",
    "print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d4fce0-04f8-4eb9-a055-f9d402215fbb",
   "metadata": {},
   "source": [
    "### Asking for code instead, and then running that code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4004e0ed-102f-412a-b1c2-b026fb7a3c0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = client.chat.completions.create(\n",
    "    model = 'gpt-3.5-turbo',\n",
    "    messages = [\n",
    "    {'role':'system','content':'You convert word problems dinto Python code. Only return the python code equivalent, no other commentary.'},\n",
    "    {'role':'user','content':'Return the python code for: What is 123456 times 456789?'}\n",
    "    ],\n",
    "    temperature = 0\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "d636c245-634a-4086-82e3-d3368e8b73c3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'123456 * 456789'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "547c553b-2efd-474e-b716-e20c508d44fd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "56393342784"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We could then just run the code!\n",
    "eval(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "daab168f-a98c-43e8-95dc-9b52b0ac7fe3",
   "metadata": {},
   "source": [
    "# Assistant with Code Interpreter\n",
    "\n",
    "Clearly, we can expand on this idea! Here we show just using the LLM to convert word problems to simple Python math formulas, but in theory the LLMs can turn any natural language word description into Python code and then simply run the code itself! This is the key idea behind the code interpreter! OpenAI Assistants allow us to connect the LLM to the code-interpreter tool. Let's explore this further!\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44addd3b-ea43-4854-9398-71d4e307a5b2",
   "metadata": {},
   "source": [
    "When creating an Assistant, you'll need to consider several parameters:\n",
    "\n",
    "* Instructions: Here, you can define how you want the Assistant to behave or respond. These instructions guide the Assistant's overall tone, style, and the type of responses it should provide.\n",
    "\n",
    "* Model Selection: You have the option to select from various GPT-3.5 or GPT-4 models, including those that are fine-tuned for specific tasks. If you're planning to use tools like the Retrieval tool, you'll need specific models like gpt-3.5-turbo-1106 or gpt-4-1106-preview.\n",
    "\n",
    "* Tools Integration: The API supports integration with tools such as the Code Interpreter and Retrieval, both of which are developed and maintained by OpenAI. These tools enhance the capabilities of your Assistant by allowing it to interpret code or retrieve information more efficiently.\n",
    "\n",
    "* Custom Functions: Another powerful feature of the API is the ability to define custom function signatures. This feature mirrors the function calling feature of the API, allowing your Assistant to perform specific tasks or operations based on your requirements.\n",
    "\n",
    "Let's begin with a very simple assistant that has access to the code interpreter tool:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "0b13a477-434d-421d-8b7e-51dce92f5c9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "assistant = client.beta.assistants.create(\n",
    "    name=\"Math Tutor\",\n",
    "    instructions=\"You convert math problems into Python code and then run the code to show the answer\",\n",
    "    tools=[{\"type\": \"code_interpreter\"}],\n",
    "    model=\"gpt-3.5-turbo\" # Check the docs for the latest models\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7d04409-ed9b-4a23-91a2-55e1ca4d8724",
   "metadata": {},
   "source": [
    "### Threads\n",
    "\n",
    "#### Creating a Thread\n",
    "\n",
    "Let's break down the concept of creating a Thread in the context of using the Assistants API with OpenAI, focusing on making it more understandable and educational.\n",
    "\n",
    "#### Understanding a \"Thread\"\n",
    "\n",
    "Think of a Thread as a digital conversation or chat room. In real life, when you start talking to someone, you have a series of exchanges that make up a conversation. Similarly, in the digital world, when a user begins interacting with an API (like the OpenAI Assistants API), this interaction is grouped into what we call a \"Thread.\"\n",
    "\n",
    "#### Why Create a Thread?\n",
    "\n",
    "1. **Organization**: Each user gets their own \"Thread,\" like a personalized chat room. This keeps conversations organized and separate from each other.\n",
    "2. **Context Management**: Within this Thread, you can pass along specific information or files that are relevant to that particular user. It's like having a personal folder for each user's conversation, keeping all their details and history in one place.\n",
    "\n",
    "#### How Threads Work\n",
    "\n",
    "- **No Size Limit**: You can think of a Thread as a never-ending conversation. There's no limit to how much you can add to it. You can continue the conversation, adding as many messages (or interactions) as needed.\n",
    "- **Optimizing Conversations**: The Assistant (in this case, the AI model you're interacting with) is pretty smart. It manages the conversation efficiently by using special techniques like truncation. This means if the conversation gets too long, the Assistant will focus on the most relevant parts to keep the interaction smooth.\n",
    "- **Simplifying Complexity**: When you use this system, you're essentially handing over the reins to the Assistant. It decides how much information (or how many input tokens) to consider for each response. This makes things easier for you because you don't have to worry about the technical aspects of managing the conversation's flow.\n",
    "\n",
    "#### What Does This Mean for You?\n",
    "\n",
    "- **Ease of Use**: You focus on what you want to ask or say, and the system handles the rest. It's designed to keep the conversation flowing without you having to manage the technical details.\n",
    "- **Cost Consideration**: While this simplifies things greatly, it also means you have less direct control over potential costs since the Assistant decides how much data to process with each interaction.\n",
    "\n",
    "In summary, creating a Thread when using the Assistants API is like starting a digital conversation with the AI, where each user gets their own personalized chat room. This system makes managing interactions simpler and more efficient, although it does mean you have less direct control over the conversation's technical aspects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "235d78a6-a5c6-49bb-8c42-b1f65a97fe34",
   "metadata": {},
   "outputs": [],
   "source": [
    "thread = client.beta.threads.create()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6b2e3b02-ea47-48d2-ae71-21aa5022804c",
   "metadata": {},
   "outputs": [],
   "source": [
    "message = client.beta.threads.messages.create(\n",
    "    thread_id=thread.id,\n",
    "    role=\"user\",\n",
    "    content=\"What is 123456 times 456789?\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e60cd3bc-8c71-401f-b95d-3a6fd3334ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ThreadMessage(id='msg_mvRbpNOQgz5piyhvQL9v3nTj', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is 123456 times 456789?'), type='text')], created_at=1701890270, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1')"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "58ab0867-770c-4d34-be5a-7b05df76c6a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_mvRbpNOQgz5piyhvQL9v3nTj', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is 123456 times 456789?'), type='text')], created_at=1701890270, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1')], object='list', first_id='msg_mvRbpNOQgz5piyhvQL9v3nTj', last_id='msg_mvRbpNOQgz5piyhvQL9v3nTj', has_more=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "client.beta.threads.messages.list(thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b11faecc-4d87-429b-a0a5-7939c3cc8d36",
   "metadata": {},
   "source": [
    "## Running the Assistant\n",
    "\n",
    "### What Does \"Run the Assistant\" Mean?\n",
    "\n",
    "Imagine the Assistant (like ChatGPT) as a helpful robot that's ready to answer questions or perform tasks. When you \"Run the Assistant,\" you're basically waking up this robot and saying, \"Hey, I have something for you to do.\"\n",
    "\n",
    "### How Does It Work?\n",
    "\n",
    "1. **Starting the Process**: You begin by creating what's called a \"Run.\" This is like pressing the 'start' button on a machine. It tells the Assistant to start paying attention to the conversation, or \"Thread,\" that's been going on.\n",
    "\n",
    "2. **Reading the Thread**: Once the Run is initiated, the Assistant starts reading through the Thread. It's like giving the robot a history of what's been discussed so far, so it can understand the context and what needs to be answered or done next.\n",
    "\n",
    "3. **Responding to Messages**: As the Run progresses, the Assistant adds its responses to the Thread. These are the messages with the role \"assistant,\" showing that they are responses from the AI, not the user.\n",
    "\n",
    "4. **Smart Context Management**: The Assistant is designed to automatically pick which previous messages it should consider while responding. This is important because it needs to know what's relevant to the current question or task. Think of it as the Assistant taking quick notes of the most important parts of the conversation to stay on track.\n",
    "\n",
    "### What Should You Know?\n",
    "\n",
    "- **Impact on Pricing and Performance**: The way the Assistant picks the context (or decides what parts of the conversation to focus on) affects two things: how much it costs to run the Assistant (since processing lots of data can be more expensive) and how well the Assistant performs (since focusing on the right context can lead to better, more accurate responses).\n",
    "- **Optimization and Evolution**: This whole process has been fine-tuned based on OpenAI's experience with building systems like ChatGPT. However, it's always evolving. What this means is that the way the Assistant works today might be improved or changed slightly in the future to make it even better.\n",
    "\n",
    "### Optional Instructions\n",
    "\n",
    "- **Customizing the Run**: You can give the Assistant special instructions for each Run. This is like telling the robot, \"This time, focus on this specific task, or answer in this particular way.\" But remember, these instructions will override the Assistant's default way of responding, so use this feature thoughtfully.\n",
    "\n",
    "In summary, \"Running the Assistant\" is the step where you activate the AI to start processing and responding to the user's messages in a conversation. It involves reading the Thread, responding appropriately, and managing the conversation's context in a way that's optimized for cost and performance. This process is constantly evolving and can be customized with specific instructions for each Run."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36456483-4e7c-4071-a78e-625831f05fc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.create(\n",
    "  thread_id=thread.id,\n",
    "  assistant_id=assistant.id,\n",
    "  instructions=\"Be very polite in your reply adn acknowledge that doing math is fun.\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "32d7c291-8109-45e3-bef4-34dfa461ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "run = client.beta.threads.runs.retrieve(\n",
    "  thread_id=thread.id,\n",
    "  run_id=run.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "28b0c8dd-67ae-4ea6-99c3-b0e168fae960",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'in_progress'"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run.status"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "5d7af8dc-9854-498a-8214-763e0d420812",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages = client.beta.threads.messages.list(\n",
    "  thread_id=thread.id\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "b711c534-e946-483f-8b86-e563dd373d30",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SyncCursorPage[ThreadMessage](data=[ThreadMessage(id='msg_ChCEghgMFzkeWA1zzkfyvtyq', assistant_id='asst_1WSNjWGUgE6PezyHQNKkO9nT', content=[MessageContentText(text=Text(annotations=[], value='The product of 123456 and 456789 is 56,393,342,784. Math can be fun!'), type='text')], created_at=1701890511, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_BCCgQ8XpQ1Nf3ExxFrldQqP4', thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1'), ThreadMessage(id='msg_mvRbpNOQgz5piyhvQL9v3nTj', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is 123456 times 456789?'), type='text')], created_at=1701890270, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1')], object='list', first_id='msg_ChCEghgMFzkeWA1zzkfyvtyq', last_id='msg_mvRbpNOQgz5piyhvQL9v3nTj', has_more=False)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "65e2aa48-8cb3-4fd7-9519-0ee52c3e57d5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'The product of 123456 and 456789 is 56,393,342,784. Math can be fun!'"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.data[0].content[0].text.value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "7720704c-3ddb-4a97-9fa1-b1f61b2a1650",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[ThreadMessage(id='msg_ChCEghgMFzkeWA1zzkfyvtyq', assistant_id='asst_1WSNjWGUgE6PezyHQNKkO9nT', content=[MessageContentText(text=Text(annotations=[], value='The product of 123456 and 456789 is 56,393,342,784. Math can be fun!'), type='text')], created_at=1701890511, file_ids=[], metadata={}, object='thread.message', role='assistant', run_id='run_BCCgQ8XpQ1Nf3ExxFrldQqP4', thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1'),\n",
       " ThreadMessage(id='msg_mvRbpNOQgz5piyhvQL9v3nTj', assistant_id=None, content=[MessageContentText(text=Text(annotations=[], value='What is 123456 times 456789?'), type='text')], created_at=1701890270, file_ids=[], metadata={}, object='thread.message', role='user', run_id=None, thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1')]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "messages.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "7641d14f-59ab-4985-8e52-fd908651f7ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The product of 123456 and 456789 is 56,393,342,784. Math can be fun!\n",
      "What is 123456 times 456789?\n"
     ]
    }
   ],
   "source": [
    "# This shows it in order of latest message\n",
    "for thread_message in messages.data:\n",
    "    print(thread_message.content[0].text.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5fd0e2ee-3f15-4a86-9961-6a6cca4e4a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "What is 123456 times 456789?\n",
      "\n",
      "\n",
      "The product of 123456 and 456789 is 56,393,342,784. Math can be fun!\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# This will show it in order of request\n",
    "for thread_message in messages.data[::-1]:\n",
    "    print(thread_message.content[0].text.value)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd058cc8-bf79-48f4-a40b-6256e4e1e9f4",
   "metadata": {},
   "source": [
    "### Detailed Run Job Information:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92766552-6cd0-4a00-97b8-de98e12dbd55",
   "metadata": {},
   "source": [
    "We can actually see the steps the assistant took internally to create the reply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "fe51c414-6444-48ab-89fa-23520d2728b2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SyncCursorPage[RunStep](data=[RunStep(id='step_WLbUQY8wvGdW8Wo6dSD9b36Z', assistant_id='asst_1WSNjWGUgE6PezyHQNKkO9nT', cancelled_at=None, completed_at=1701890511, created_at=1701890511, expired_at=None, failed_at=None, last_error=None, metadata=None, object='thread.run.step', run_id='run_BCCgQ8XpQ1Nf3ExxFrldQqP4', status='completed', step_details=MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_ChCEghgMFzkeWA1zzkfyvtyq'), type='message_creation'), thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1', type='message_creation', expires_at=None), RunStep(id='step_Yq1fMkCGydu2nwaS70D9uyK4', assistant_id='asst_1WSNjWGUgE6PezyHQNKkO9nT', cancelled_at=None, completed_at=1701890511, created_at=1701890502, expired_at=None, failed_at=None, last_error=None, metadata=None, object='thread.run.step', run_id='run_BCCgQ8XpQ1Nf3ExxFrldQqP4', status='completed', step_details=ToolCallsStepDetails(tool_calls=[CodeToolCall(id='call_jpkKaq8hFuV009UpeiXkBePn', code_interpreter=CodeInterpreter(input='result = 123456 * 456789\\nresult', outputs=[CodeInterpreterOutputLogs(logs='56393342784', type='logs')]), type='code_interpreter')], type='tool_calls'), thread_id='thread_MPOEGvEvRqBWQYeyLfScWGD1', type='tool_calls', expires_at=None)], object='list', first_id='step_WLbUQY8wvGdW8Wo6dSD9b36Z', last_id='step_Yq1fMkCGydu2nwaS70D9uyK4', has_more=False)\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "client = OpenAI()\n",
    "\n",
    "run_steps = client.beta.threads.runs.steps.list(\n",
    "    thread_id=thread.id,\n",
    "    run_id=run.id\n",
    ")\n",
    "print(run_steps)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "beef1aeb-71eb-4b64-8928-75e4346be557",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MessageCreationStepDetails(message_creation=MessageCreation(message_id='msg_ChCEghgMFzkeWA1zzkfyvtyq'), type='message_creation')\n",
      "\n",
      "\n",
      "ToolCallsStepDetails(tool_calls=[CodeToolCall(id='call_jpkKaq8hFuV009UpeiXkBePn', code_interpreter=CodeInterpreter(input='result = 123456 * 456789\\nresult', outputs=[CodeInterpreterOutputLogs(logs='56393342784', type='logs')]), type='code_interpreter')], type='tool_calls')\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for step in run_steps:\n",
    "    print(step.step_details)\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c78c5c10-f301-422c-beb9-3655822e37d2",
   "metadata": {},
   "source": [
    "## Listing and Deleting Assistants"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "11352321-488b-4616-8b02-37578abe6ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Assistant(id='asst_1WSNjWGUgE6PezyHQNKkO9nT', created_at=1701890074, description=None, file_ids=[], instructions='You convert math problems into Python code and then run the code to show the answer', metadata={}, model='gpt-3.5-turbo', name='Math Tutor', object='assistant', tools=[ToolCodeInterpreter(type='code_interpreter')])]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "34152753-32c4-43f1-8812-925991499c06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AssistantDeleted(id='asst_1WSNjWGUgE6PezyHQNKkO9nT', deleted=True, object='assistant.deleted')\n"
     ]
    }
   ],
   "source": [
    "response = client.beta.assistants.delete('asst_1WSNjWGUgE6PezyHQNKkO9nT')\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9f71a776-6ee4-4763-9fed-26b62b545d1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "my_assistants = client.beta.assistants.list(\n",
    "    order=\"desc\",\n",
    "    limit=\"20\",\n",
    ")\n",
    "print(my_assistants.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb791e61-cc4f-461f-a209-7a7edf838da9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
